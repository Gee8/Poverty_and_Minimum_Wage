{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_network_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GI6E8nGrGXC"
      },
      "source": [
        "# Build Neural Network\n",
        "\n",
        "This is a basic single-neuron, single-layer model using a test dataset.\n",
        "\n",
        "If we are not changing the data structure of our neural network or function, this template can be used for linear and non-linear data. \n",
        "\n",
        "The process of **model -> fit -> predict/transform** follows the same general steps across all of data science:\n",
        "\n",
        "* Decide on a model\n",
        "* Create a model instance\n",
        "* Split into training and testing sets and preprocess the data\n",
        "* Train/fit the training data to the model after creating and compiling the model (\"train\" and \"fit\" are used interchangeably in Python libraries as well as the data field.)\n",
        "* Use the model for predictions and transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7yBmwHgrH7Z"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCFYLneid4St",
        "outputId": "5cb7a51c-3ca5-4091-bf98-6f801df12b02"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWdS5YKlmHBB"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "7g8RO12mq1E-",
        "outputId": "c06dc439-8cd2-4d2c-fe75-ae17fd1f1dbc"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-259c18c2-ada6-4eee-9820-20d95daa0bb7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-259c18c2-ada6-4eee-9820-20d95daa0bb7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-REP24siTru"
      },
      "source": [
        "# Import our dependencies\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import sklearn as skl\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from pyspark import SparkFiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxut_w56jged"
      },
      "source": [
        "## Import Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-p5mpTrjiww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "73b8ddac-0885-4095-e176-4b34e9de42e2"
      },
      "source": [
        "# Import and read our input dataset\n",
        "df = pd.read_csv('file_name.csv')\n",
        "df.head()\n",
        "\n",
        "# OR Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "#url = \"https://s3.amazonaws.com/dataviz-curriculum/day_1/food.csv\"\n",
        "url = \"database-1.czpjmlarn3xk.us-east-2.rds.amazonaws.com\"\n",
        "\n",
        "# Import into a DataFrame\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"food.csv\"), sep=\",\", header=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-599c2d3d1a81>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    database-1.czpjmlarn3xk.us-east-2.rds.amazonaws.com\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnt5XCNCihVs"
      },
      "source": [
        "## Generate Dummy Data -- NOTE - This may not be necessary for our project \n",
        "\n",
        "* Create the dummy data using Scikit-learn's **make_blobs method**. The make_blobs is used to create sample values and contains many parameters that change the shape and values of the sample dataset. \n",
        "* **n_samples** = number of sample data\n",
        "* **centers** = argument specifies the number of clusters in the dataset; in this case there are two clusters or number of features (known as x- and y-axis values that are linearly separable into two groups\n",
        "* **random_state** = Ensures reproducibility of this dataset: even though the numbers in this dataset are generated pseudo-randomly,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vws1dTP0ic5c"
      },
      "source": [
        "# Generate dummy dataset\n",
        "X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=78)\n",
        "\n",
        "# Creating a DataFrame with the dummy data\n",
        "df = pd.DataFrame(X, columns=[\"Feature 1\", \"Feature 2\"])\n",
        "df[\"Target\"] = y\n",
        "\n",
        "# Plotting the dummy data\n",
        "df.plot.scatter(x=\"Feature 1\", y=\"Feature 2\", c=\"Target\", colormap=\"winter\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgQzdW5N7UW1"
      },
      "source": [
        "## Pre-Process Data\n",
        "\n",
        "* Remove non-beneficial columns\n",
        "* Check unique value counts\n",
        "* Convert strings or categorical values to numerical values\n",
        "* Encode columns\n",
        "* Bin or bucket categorical (columns) to reduce unique categorical values in a dataset is known \n",
        "* Large gaps between numerical values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyYUFhdy8lEq"
      },
      "source": [
        "### Drop non-beneficial columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDVmsP4q-5tb"
      },
      "source": [
        "# Drop the non-beneficial columns\n",
        "df = df.drop(columns=[\"\", \"N\"], axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI9Lziuv_EfO"
      },
      "source": [
        "### Determine the number of unique values in each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4snB-Sz_LwH"
      },
      "source": [
        "# Determine the number of unique values in each column\n",
        "cnt = df.nunique(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRpHBhPI9W7q"
      },
      "source": [
        "### Look at value counts for binning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTFRDHw9foi"
      },
      "source": [
        "# Check for unique values is to use the Pandas DataFrame's value_counts method\n",
        "application_counts = df.column_name.value_counts()\n",
        "application_counts "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNWKy-nd9pmx"
      },
      "source": [
        "### Visualize density\n",
        "\n",
        "Use density plot to determine which values are uncommon enough to bucket into the \"other\" category. Dentify where the value counts \"fall off\" and set the threshold within this region. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qQKQupv9r8p"
      },
      "source": [
        "# Visualize the value counts of APPLICATION_TYPE\n",
        "application_counts.plot.density()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I3BxD8R9xW9"
      },
      "source": [
        "### Bin categorical variables\n",
        "* Collapse all of the infrequent and rare categorical values into a single \"other\" category.\n",
        "* Create generalized categorical "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh95W1VF9z5v"
      },
      "source": [
        "# Determine which values to replace if counts are less than ...?\n",
        "replace_application = list(application_counts[application_counts < 500].index)\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in replace_application:\n",
        "    application_df.column_name = application_df.column_name.replace(app,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df.column_name.value_counts()\n",
        "\n",
        "# This reduces the number of unique values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V61DeRXr-UId"
      },
      "source": [
        "# Generate our categorical variable lists\n",
        "application_cat = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
        "application_cat\n",
        "\n",
        "# Generate categorical list prior to encoding all categorical data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8VA0bUiAClM"
      },
      "source": [
        "### Encoding\n",
        "After reducing the number of unique values in the country variable, transpose the variable using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ZlDYsy-YIs"
      },
      "source": [
        "# Create a OneHotEncoder instance\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the OneHotEncoder using the categorical variable list\n",
        "encode_df = pd.DataFrame(enc.fit_transform(df[application_cat]))\n",
        "\n",
        "# Add the encoded variable names to the dataframe (rename encoded column)\n",
        "encode_df.columns = enc.get_feature_names(application_cat)\n",
        "encode_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzzyuW9LAR7-"
      },
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "merged_df = df.merge(encode_df,left_index=True,right_index=True).drop(application_cat,1)\n",
        "merged_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k9ODyPDkYEb"
      },
      "source": [
        "## Split Data Into Training and Test Datasets \n",
        "\n",
        "* Use Scikit-learn's train_test_split method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95VPfG1SkfwZ"
      },
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = merged_df[\"\"].values\n",
        "X = merged_df.drop([\"\"], axis=1).values\n",
        "merged_df\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset using sklearn to split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KGHn95Gkkxm"
      },
      "source": [
        "## Prepare Dataset For Our Neural Network Model\n",
        "## Standardize Data\n",
        "\n",
        "* First normalize or standardize numerical variables to ensure that our neural network does not focus on outliers and can apply proper weights to each input\n",
        "* The more the input variables are normalized to the same scale, the more stable the neural network model is, and the better the neural network model will generalize.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN0KMTvGlbUM"
      },
      "source": [
        "# Create scaler instance\n",
        "X_scaler = skl.preprocessing.StandardScaler()\n",
        "\n",
        "# Fit the scaler\n",
        "X_scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGPqRNtb8wMV"
      },
      "source": [
        "## Create Keras Sequential Neural Network Model\n",
        "To create the neural network, first create our Sequential modelKeras classes:\n",
        "\n",
        "* The **Sequential** class is a linear stack of neural network layers, where data flows from one layer to the next. \n",
        "* The generalized **Dense** class allows us to add layers within the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkVHmW-98xyG"
      },
      "source": [
        "# Create the Keras Sequential model\n",
        "nn_model = tf.keras.models.Sequential()\n",
        "\n",
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 =  80\n",
        "hidden_nodes_layer2 = 30\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSkzO8MJluTP"
      },
      "source": [
        "## Create The Layers\n",
        "### First Dense Layer\n",
        "Contains inputs and a hidden layer of neurons:\n",
        "* The **units** parameter indicates how many neurons we want in the hidden layer\n",
        "* The **input_dim** parameter indicates how many inputs will be in the model\n",
        "* The **activation** parameter indicates which activation function to use\n",
        "\n",
        "        * Use ReLU for nonlinear relationships\n",
        "        * Use Signmoid for binary classification output\n",
        "\n",
        "### Output Layer\n",
        "* **nn_model** object will store the entire architecture of our neural network model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_kiZFeBl_sY"
      },
      "source": [
        "# This is for a basic model example\n",
        "# Add our first Dense layer, including the input layer\n",
        "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"relu\", input_dim= 2))\n",
        "\n",
        "    # By default, Dense layer will look for linear relationships\n",
        "    # Example has single neuron (units), two inputs (input_dim), relu (activation function)\n",
        "\n",
        "# Add the output layer that uses a probability activation function\n",
        "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    # Provide the number of output neurons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-O_m_Ou8fFm"
      },
      "source": [
        "## Check Model Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdPN33IvBeAD"
      },
      "source": [
        "# Check the structure of the Sequential model\n",
        "nn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSI7JGMVB8sD"
      },
      "source": [
        "## Compile The Model\n",
        "\n",
        "Inform the model how it should train using the input data. \n",
        "\n",
        "Depending on the function of the neural network, we'll have to compile the neural network using a specific optimization function and loss metric. \n",
        "\n",
        "*  **optimization function** shapes and molds a neural network model while it is being trained to ensure that it performs to the best of its ability. \n",
        "* **loss metric** is used by to score the performance of the model through each iteration and epoch by evaluating the inaccuracy of a single input. \n",
        "* **adam optimizer** is used to enhance the performance of classification neural network\n",
        "* **loss function** is used binary_crossentropy to evaluate a binary classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL1WMpGuCAky"
      },
      "source": [
        "# Compile the Sequential model together and customize metrics\n",
        "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NgDbUv_xnB6"
      },
      "source": [
        "There are two main types of evaluation metrics—\n",
        "\n",
        "* Predictive **accuracy** - use accuracy for classification models. For model predictive accuracy, the higher the number the better. \n",
        "* **Mean squared error (MSE)** - Use for regression models. MSE should reduce to zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p571DxnTBh0Q"
      },
      "source": [
        "# Train (Fit) The Model\n",
        "Yse the fit method and provide the x training values and y training values, as well as the number of epochs. Each epoch is a complete pass through the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdiUuf5rDUkD"
      },
      "source": [
        "# Fit the model to the training data\n",
        "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)\n",
        "\n",
        "# epochs can be adjusted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xib_N4YhBh3H"
      },
      "source": [
        "## Visualize Model's Data Lost\n",
        "\n",
        "Model object stores the loss and accuracy metrics across all epochs, which we can use to visualize the training progress. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDIreB_mJwzy"
      },
      "source": [
        "# Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
        "\n",
        "# Plot the loss\n",
        "history_df.plot(y=\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfbzaORWBh6Y"
      },
      "source": [
        "## Plot Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvKoUclHKyf7"
      },
      "source": [
        "# Plot the accuracy\n",
        "history_df.plot(y=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFJb8Lw_sYHQ"
      },
      "source": [
        "## Evaluate Model Performance Using The Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGYRMR9nBhLD"
      },
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO1pjRNgtIE0"
      },
      "source": [
        "## Predict Classification Using A New Dataset -- May Not Be Needed For Our Project\n",
        "Now that we have a trained neural network model and we have verified its performance using a test dataset, we can apply this model to novel datasets and predict the classification of a data point. In our Sequential model, we can use the predict method to generate predictions on new data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3efNh7IPBhOp"
      },
      "source": [
        "# Predict the classification of a new set of blob data\n",
        "new_X, new_Y = make_blobs(n_samples=10, centers=2, n_features=2, random_state=78)\n",
        "new_X_scaled = X_scaler.transform(new_X)\n",
        "(nn_model.predict(new_X_scaled) > 0.5).astype(\"int32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY_ImPZAM0KZ"
      },
      "source": [
        "## Create The Checkpoint And CallBack Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGXMroGoMtpz"
      },
      "source": [
        "# Import checkpoint dependencies\n",
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the checkpoint path and filenames\n",
        "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
        "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWdF21lwMzSk"
      },
      "source": [
        "# Create a callback that saves the model's weights every 5 epochs.\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch')\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzdoJ9v4M9l8"
      },
      "source": [
        "# Save and export your results to an HDF5 file and name it AlphabetSoupCharity.h5.\n",
        "nn.save(\"AlphabetSoupCharity.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv0y4BJcq-Yd"
      },
      "source": [
        "# Optimization Techniques\n",
        "\n",
        "### References:\n",
        "* Optimization Functions\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "* Loss Metrics\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "* Keras Documentation\n",
        "https://www.tensorflow.org/guide/keras/sequential_model\n",
        "\n",
        "### Techniques:\n",
        "1. Add more neurons to a hidden layer(s) of our neural network can help to generate a well-performing model faster than using a single-neuron, single-layer neural network:\n",
        "    * To find optimal weights—faster\n",
        "    * Each neuron can focus on different features to identify nonlinear smarter\n",
        "    * To fixate less likely on complex variables—more robust\n",
        "\n",
        "  Limitations: \n",
        "  * Adding too many neurons --> overfitting and computation resources\n",
        "  * Large number of neurons requires equally large training dataset and more  epochs\n",
        "\n",
        "### Good rule of thumb for a basic neural network is to have two to three times the amount of neurons in the hidden layer as the number of inputs.\n",
        "\n",
        "2. Check out your input dataset to remove outliers \n",
        "3. Add additional hidden layers to allow neurons to train on activated input values, instead of looking at new training data. A neural network with multiple layers can identify nonlinear characteristics of the input data without requiring more input data.\n",
        "4. Use a different activation function for the hidden layers. Depending on the shape and dimensionality of the input data, one activation function may focus on specific characteristics of the input values, while another activation function may focus on others.\n",
        "5. Add additional epochs to the training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs95kfHM6t8B"
      },
      "source": [
        "### Activation Functions\n",
        "\n",
        "* **sigmoid** function values are normalized to a probability between 0 and 1, which is ideal for binary classification.\n",
        "* **tanh** function can be used for classification or regression, and it expands the range between -1 and 1.\n",
        "* **ReLU** function is ideal for looking at positive nonlinear input data for classification or regression.\n",
        "* **Leaky ReLU** function is a good alternative for nonlinear input data with many negative inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytbXXVZrxILr"
      },
      "source": [
        "### Adding More Neurons Steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPTyESh_3mm5"
      },
      "source": [
        "# Generate our new Sequential model\n",
        "new_model = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4bwKa_B3nmh"
      },
      "source": [
        "# Add the input and hidden layer\n",
        "number_inputs = 2\n",
        "number_hidden_nodes = 6\n",
        "    # Adding 6 neurons\n",
        "    \n",
        "new_model.add(tf.keras.layers.Dense(units=number_hidden_nodes, activation=\"relu\", input_dim=number_inputs))\n",
        "\n",
        "# Add the output layer that uses a probability activation function\n",
        "new_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXOwThiU4zyY"
      },
      "source": [
        "# Compile the Sequential model together and customize metrics\n",
        "new_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model to the training data\n",
        "new_fit_model = new_model.fit(X_moon_train_scaled, y_moon_train, epochs=100, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}